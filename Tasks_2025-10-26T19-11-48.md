[ ] NAME:Current Task List DESCRIPTION:Root task for conversation __NEW_AGENT__
-[ ] NAME:Acoustic Source Localization App (macOS) - Multi-Phase Plan DESCRIPTION:Plan and execute an end-to-end macOS application for acoustic source localization with remote microphones, real-time DSP, synchronization, and visualization.
--[ ] NAME:Phase 1: Core macOS audio capture infrastructure DESCRIPTION:Set up AVAudioEngine input capture, enumerate microphones (USB/Bluetooth/built-in), establish Aggregate Device strategy, basic buffer handling at 48 kHz mono, and logging. Compile and verify.
---[/] NAME:Examine the existing Swift macOS project structure DESCRIPTION:Discover the Xcode/SwiftPM setup, schemes/targets, entry points, and current audio code. Identify where to integrate AVAudioEngine and device enumeration.
---[ ] NAME:Set up AVAudioEngine for audio input capture DESCRIPTION:Initialize AVAudioEngine, request mic permission, configure input node tap, and prepare to deliver 48 kHz mono buffers downstream.
---[ ] NAME:Implement microphone device enumeration (USB, Bluetooth, built-in) DESCRIPTION:Use Core Audio HAL to list input-capable devices with properties (UID, name, manufacturer, sample rates, channel counts).
---[ ] NAME:Research and implement Core Audio Aggregate Device creation DESCRIPTION:Decide manual (Audio MIDI Setup) vs programmatic creation first. If programmatic, add HAL code to build an Aggregate Device and enable drift correction.
---[ ] NAME:Create basic audio buffer handling and format conversion to 48 kHz mono DESCRIPTION:Downmix/convert incoming buffers to uniform 48 kHz mono Float32; set channel mapping for aggregated inputs.
---[ ] NAME:Add basic logging/debugging for captured audio streams DESCRIPTION:Log device selection, format, buffer timing, peak/RMS meters; add lightweight on-screen or console indicators.
---[ ] NAME:Build and verify the project compiles without errors (Phase 1) DESCRIPTION:Run swift build or xcodebuild for the macOS target and ensure successful compilation; address errors/warnings if any.
--[ ] NAME:Phase 2: DSP foundation (GCC-PHAT for TDOA) DESCRIPTION:Implement GCC-PHAT using Accelerate/vDSP for pairwise TDOA estimation, with windowing/overlap, peak detection, and basic unit tests. Compile and verify.
--[ ] NAME:Phase 3: Remote microphone infrastructure (WebRTC) DESCRIPTION:Integrate WebRTC in the macOS app (LiveKit Swift SDK or stasel/WebRTC). Subscribe to remote audio tracks as additional inputs. Compile and verify.
--[ ] NAME:Phase 4: Web application for remote microphone (Next.js on Vercel) DESCRIPTION:Build a minimal web client that captures mic with disabled AGC/NS/EC and publishes via WebRTC (prefer LiveKit). Deploy on Vercel. Verify phone-to-cloud publishing.
--[ ] NAME:Phase 5: Audio stream synchronization and alignment DESCRIPTION:Implement jitter buffers, RTP/RTCP timestamp mapping for coarse sync, and GCC-PHAT-based fine alignment with drift compensation/resampling.
--[ ] NAME:Phase 6: Source localization algorithms and visualization DESCRIPTION:Fuse TDOAs into DoA/triangulation. Implement geometric solver and confidence metrics. Build real-time direction/location visualization.
--[ ] NAME:Phase 7: UI/UX implementation (macOS dashboard) DESCRIPTION:Design and implement a clean, cute dashboard: mic status, connection indicators, level meters, and direction/location visualization. Compile and verify.
--[ ] NAME:Phase 8: Testing, calibration, and optimization DESCRIPTION:Add calibration flows, performance profiling, and accuracy tests. Optimize DSP (vectorization), tune buffers, and document procedures.
-[ ] NAME:Current Task List DESCRIPTION:Root task for conversation __NEW_AGENT__
--[ ] NAME:Acoustic Source Localization App (macOS) - Multi-Phase Plan DESCRIPTION:Plan and execute an end-to-end macOS application for acoustic source localization with remote microphones, real-time DSP, synchronization, and visualization.
---[ ] NAME:Phase 1: Core macOS audio capture infrastructure DESCRIPTION:Set up AVAudioEngine input capture, enumerate microphones (USB/Bluetooth/built-in), establish Aggregate Device strategy, basic buffer handling at 48 kHz mono, and logging. Compile and verify.
----[/] NAME:Examine the existing Swift macOS project structure DESCRIPTION:Discover the Xcode/SwiftPM setup, schemes/targets, entry points, and current audio code. Identify where to integrate AVAudioEngine and device enumeration.
----[ ] NAME:Set up AVAudioEngine for audio input capture DESCRIPTION:Initialize AVAudioEngine, request mic permission, configure input node tap, and prepare to deliver 48 kHz mono buffers downstream.
----[ ] NAME:Implement microphone device enumeration (USB, Bluetooth, built-in) DESCRIPTION:Use Core Audio HAL to list input-capable devices with properties (UID, name, manufacturer, sample rates, channel counts).
----[ ] NAME:Research and implement Core Audio Aggregate Device creation DESCRIPTION:Decide manual (Audio MIDI Setup) vs programmatic creation first. If programmatic, add HAL code to build an Aggregate Device and enable drift correction.
----[ ] NAME:Create basic audio buffer handling and format conversion to 48 kHz mono DESCRIPTION:Downmix/convert incoming buffers to uniform 48 kHz mono Float32; set channel mapping for aggregated inputs.
----[ ] NAME:Add basic logging/debugging for captured audio streams DESCRIPTION:Log device selection, format, buffer timing, peak/RMS meters; add lightweight on-screen or console indicators.
----[ ] NAME:Build and verify the project compiles without errors (Phase 1) DESCRIPTION:Run swift build or xcodebuild for the macOS target and ensure successful compilation; address errors/warnings if any.
---[ ] NAME:Phase 2: DSP foundation (GCC-PHAT for TDOA) DESCRIPTION:Implement GCC-PHAT using Accelerate/vDSP for pairwise TDOA estimation, with windowing/overlap, peak detection, and basic unit tests. Compile and verify.
---[ ] NAME:Phase 3: Remote microphone infrastructure (WebRTC) DESCRIPTION:Integrate WebRTC in the macOS app (LiveKit Swift SDK or stasel/WebRTC). Subscribe to remote audio tracks as additional inputs. Compile and verify.
---[ ] NAME:Phase 4: Web application for remote microphone (Next.js on Vercel) DESCRIPTION:Build a minimal web client that captures mic with disabled AGC/NS/EC and publishes via WebRTC (prefer LiveKit). Deploy on Vercel. Verify phone-to-cloud publishing.
---[ ] NAME:Phase 5: Audio stream synchronization and alignment DESCRIPTION:Implement jitter buffers, RTP/RTCP timestamp mapping for coarse sync, and GCC-PHAT-based fine alignment with drift compensation/resampling.
---[ ] NAME:Phase 6: Source localization algorithms and visualization DESCRIPTION:Fuse TDOAs into DoA/triangulation. Implement geometric solver and confidence metrics. Build real-time direction/location visualization.
---[ ] NAME:Phase 7: UI/UX implementation (macOS dashboard) DESCRIPTION:Design and implement a clean, cute dashboard: mic status, connection indicators, level meters, and direction/location visualization. Compile and verify.
---[ ] NAME:Phase 8: Testing, calibration, and optimization DESCRIPTION:Add calibration flows, performance profiling, and accuracy tests. Optimize DSP (vectorization), tune buffers, and document procedures.
-[/] NAME:Examine the existing Swift macOS project structure DESCRIPTION:Discover the Xcode/SwiftPM setup, schemes/targets, entry points, and current audio code. Identify where to integrate AVAudioEngine and device enumeration.
-[ ] NAME:Current Task List DESCRIPTION:Root task for conversation __NEW_AGENT__
--[ ] NAME:Acoustic Source Localization App (macOS) - Multi-Phase Plan DESCRIPTION:Plan and execute an end-to-end macOS application for acoustic source localization with remote microphones, real-time DSP, synchronization, and visualization.
---[ ] NAME:Phase 1: Core macOS audio capture infrastructure DESCRIPTION:Set up AVAudioEngine input capture, enumerate microphones (USB/Bluetooth/built-in), establish Aggregate Device strategy, basic buffer handling at 48 kHz mono, and logging. Compile and verify.
----[/] NAME:Examine the existing Swift macOS project structure DESCRIPTION:Discover the Xcode/SwiftPM setup, schemes/targets, entry points, and current audio code. Identify where to integrate AVAudioEngine and device enumeration.
----[ ] NAME:Set up AVAudioEngine for audio input capture DESCRIPTION:Initialize AVAudioEngine, request mic permission, configure input node tap, and prepare to deliver 48 kHz mono buffers downstream.
----[ ] NAME:Implement microphone device enumeration (USB, Bluetooth, built-in) DESCRIPTION:Use Core Audio HAL to list input-capable devices with properties (UID, name, manufacturer, sample rates, channel counts).
----[ ] NAME:Research and implement Core Audio Aggregate Device creation DESCRIPTION:Decide manual (Audio MIDI Setup) vs programmatic creation first. If programmatic, add HAL code to build an Aggregate Device and enable drift correction.
----[ ] NAME:Create basic audio buffer handling and format conversion to 48 kHz mono DESCRIPTION:Downmix/convert incoming buffers to uniform 48 kHz mono Float32; set channel mapping for aggregated inputs.
----[ ] NAME:Add basic logging/debugging for captured audio streams DESCRIPTION:Log device selection, format, buffer timing, peak/RMS meters; add lightweight on-screen or console indicators.
----[ ] NAME:Build and verify the project compiles without errors (Phase 1) DESCRIPTION:Run swift build or xcodebuild for the macOS target and ensure successful compilation; address errors/warnings if any.
---[ ] NAME:Phase 2: DSP foundation (GCC-PHAT for TDOA) DESCRIPTION:Implement GCC-PHAT using Accelerate/vDSP for pairwise TDOA estimation, with windowing/overlap, peak detection, and basic unit tests. Compile and verify.
---[ ] NAME:Phase 3: Remote microphone infrastructure (WebRTC) DESCRIPTION:Integrate WebRTC in the macOS app (LiveKit Swift SDK or stasel/WebRTC). Subscribe to remote audio tracks as additional inputs. Compile and verify.
---[ ] NAME:Phase 4: Web application for remote microphone (Next.js on Vercel) DESCRIPTION:Build a minimal web client that captures mic with disabled AGC/NS/EC and publishes via WebRTC (prefer LiveKit). Deploy on Vercel. Verify phone-to-cloud publishing.
---[ ] NAME:Phase 5: Audio stream synchronization and alignment DESCRIPTION:Implement jitter buffers, RTP/RTCP timestamp mapping for coarse sync, and GCC-PHAT-based fine alignment with drift compensation/resampling.
---[ ] NAME:Phase 6: Source localization algorithms and visualization DESCRIPTION:Fuse TDOAs into DoA/triangulation. Implement geometric solver and confidence metrics. Build real-time direction/location visualization.
---[ ] NAME:Phase 7: UI/UX implementation (macOS dashboard) DESCRIPTION:Design and implement a clean, cute dashboard: mic status, connection indicators, level meters, and direction/location visualization. Compile and verify.
---[ ] NAME:Phase 8: Testing, calibration, and optimization DESCRIPTION:Add calibration flows, performance profiling, and accuracy tests. Optimize DSP (vectorization), tune buffers, and document procedures.
--[ ] NAME:Current Task List DESCRIPTION:Root task for conversation __NEW_AGENT__
---[ ] NAME:Acoustic Source Localization App (macOS) - Multi-Phase Plan DESCRIPTION:Plan and execute an end-to-end macOS application for acoustic source localization with remote microphones, real-time DSP, synchronization, and visualization.
----[ ] NAME:Phase 1: Core macOS audio capture infrastructure DESCRIPTION:Set up AVAudioEngine input capture, enumerate microphones (USB/Bluetooth/built-in), establish Aggregate Device strategy, basic buffer handling at 48 kHz mono, and logging. Compile and verify.
-----[x] NAME:Examine the existing Swift macOS project structure DESCRIPTION:Discover the Xcode/SwiftPM setup, schemes/targets, entry points, and current audio code. Identify where to integrate AVAudioEngine and device enumeration.
-----[/] NAME:Set up AVAudioEngine for audio input capture DESCRIPTION:Initialize AVAudioEngine, request mic permission, configure input node tap, and prepare to deliver 48 kHz mono buffers downstream.
-----[ ] NAME:Implement microphone device enumeration (USB, Bluetooth, built-in) DESCRIPTION:Use Core Audio HAL to list input-capable devices with properties (UID, name, manufacturer, sample rates, channel counts).
-----[ ] NAME:Research and implement Core Audio Aggregate Device creation DESCRIPTION:Decide manual (Audio MIDI Setup) vs programmatic creation first. If programmatic, add HAL code to build an Aggregate Device and enable drift correction.
-----[ ] NAME:Create basic audio buffer handling and format conversion to 48 kHz mono DESCRIPTION:Downmix/convert incoming buffers to uniform 48 kHz mono Float32; set channel mapping for aggregated inputs.
-----[ ] NAME:Add basic logging/debugging for captured audio streams DESCRIPTION:Log device selection, format, buffer timing, peak/RMS meters; add lightweight on-screen or console indicators.
-----[ ] NAME:Build and verify the project compiles without errors (Phase 1) DESCRIPTION:Run swift build or xcodebuild for the macOS target and ensure successful compilation; address errors/warnings if any.
----[ ] NAME:Phase 2: DSP foundation (GCC-PHAT for TDOA) DESCRIPTION:Implement GCC-PHAT using Accelerate/vDSP for pairwise TDOA estimation, with windowing/overlap, peak detection, and basic unit tests. Compile and verify.
----[ ] NAME:Phase 3: Remote microphone infrastructure (WebRTC) DESCRIPTION:Integrate WebRTC in the macOS app (LiveKit Swift SDK or stasel/WebRTC). Subscribe to remote audio tracks as additional inputs. Compile and verify.
----[ ] NAME:Phase 4: Web application for remote microphone (Next.js on Vercel) DESCRIPTION:Build a minimal web client that captures mic with disabled AGC/NS/EC and publishes via WebRTC (prefer LiveKit). Deploy on Vercel. Verify phone-to-cloud publishing.
----[ ] NAME:Phase 5: Audio stream synchronization and alignment DESCRIPTION:Implement jitter buffers, RTP/RTCP timestamp mapping for coarse sync, and GCC-PHAT-based fine alignment with drift compensation/resampling.
----[ ] NAME:Phase 6: Source localization algorithms and visualization DESCRIPTION:Fuse TDOAs into DoA/triangulation. Implement geometric solver and confidence metrics. Build real-time direction/location visualization.
----[ ] NAME:Phase 7: UI/UX implementation (macOS dashboard) DESCRIPTION:Design and implement a clean, cute dashboard: mic status, connection indicators, level meters, and direction/location visualization. Compile and verify.
----[ ] NAME:Phase 8: Testing, calibration, and optimization DESCRIPTION:Add calibration flows, performance profiling, and accuracy tests. Optimize DSP (vectorization), tune buffers, and document procedures.
--[/] NAME:Examine the existing Swift macOS project structure DESCRIPTION:Discover the Xcode/SwiftPM setup, schemes/targets, entry points, and current audio code. Identify where to integrate AVAudioEngine and device enumeration.
-[ ] NAME:Set up AVAudioEngine for audio input capture DESCRIPTION:Initialize AVAudioEngine, request mic permission, configure input node tap, and prepare to deliver 48 kHz mono buffers downstream.
-[-] NAME:Core Audio Infrastructure DESCRIPTION:Set up multi-microphone audio capture using Core Audio and AVFoundation
--[-] NAME:Audio Device Manager DESCRIPTION:Create manager for enumerating and handling multiple audio input devices (USB, Bluetooth, built-in)
--[-] NAME:Aggregate Device Builder DESCRIPTION:Implement Core Audio Aggregate Device creation with drift correction
--[-] NAME:Audio Capture Engine DESCRIPTION:Build AVAudioEngine-based capture pipeline for multi-channel audio at 48kHz
--[-] NAME:Audio Stream Synchronizer DESCRIPTION:Implement time alignment and jitter buffer for multiple audio streams
-[-] NAME:DSP & Localization Engine DESCRIPTION:Implement GCC-PHAT algorithm using Accelerate framework for TDOA estimation
--[-] NAME:GCC-PHAT Implementation DESCRIPTION:Implement GCC-PHAT using Accelerate vDSP for cross-correlation and FFT
--[-] NAME:TDOA Estimator DESCRIPTION:Build time-difference-of-arrival estimator from GCC-PHAT peaks
--[-] NAME:Geometric Solver DESCRIPTION:Implement triangulation/DoA solver from TDOA measurements
--[-] NAME:Localization Visualizer DESCRIPTION:Create real-time visualization of detected sound source direction/location
-[-] NAME:Remote Microphone System DESCRIPTION:Build WebRTC-based remote microphone streaming (web to macOS)
-[-] NAME:UI/UX Implementation DESCRIPTION:Create SwiftUI dashboard with visualization for sound source location
-[-] NAME:Web Application (Vercel) DESCRIPTION:Build Next.js web app for mobile phone microphone streaming
-[ ] NAME:Current Task List DESCRIPTION:Root task for conversation __NEW_AGENT__
--[/] NAME:Phase 1: Core Audio Infrastructure DESCRIPTION:Set up multi-microphone capture, Core Audio Aggregate Device, and AVAudioEngine
--[ ] NAME:Phase 2: DSP & Localization Algorithms DESCRIPTION:Implement GCC-PHAT, TDOA estimation, and triangulation using Accelerate/vDSP
--[ ] NAME:Phase 3: Remote Microphone Support (WebRTC) DESCRIPTION:Integrate LiveKit Swift SDK for remote phone microphone streaming
--[ ] NAME:Phase 4: Web Application (Vercel) DESCRIPTION:Build Next.js web app for remote microphone browser interface
--[ ] NAME:Phase 5: UI/UX & Visualization DESCRIPTION:Create cute macOS dashboard with real-time sound source visualization
--[ ] NAME:Phase 6: Testing & Integration DESCRIPTION:Write tests, validate multi-mic sync, and end-to-end testing